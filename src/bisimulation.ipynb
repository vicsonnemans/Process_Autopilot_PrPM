{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "from MDP_functions import get_data, find_next_state, transition_probabilities_faster\n",
    "from utils import *\n",
    "from MDP_generator import *\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = InterpretableLoanMDP()\n",
    "dataset = 'simulation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisimulation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== State Abstraction: k_means with k: 10 ===\n",
      "Simulating the environment with 52458 distinct original states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cases: 100%|██████████| 30000/30000 [00:17<00:00, 1681.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 90 distinct states (0.17%) of original state space) (k=10)\n",
      "Precomputing transitions and encoded states...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "States: 100%|██████████| 52458/52458 [00:02<00:00, 21580.04it/s]\n",
      "Computing cluster distances: 100%|██████████| 90/90 [14:42<00:00,  9.80s/cluster, avg_bisimilarity_distance=0.00]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Bisimilarity Distance of k_means with 90 blocks: 13.74\n"
     ]
    }
   ],
   "source": [
    "state_abstractions = [('structural', 1), ('k_means_features', 10), ('k_means_features', 50), ('k_means_features', 200), ('k_means', 10), ('k_means', 50), ('k_means', 200), ('last_action', 0)]\n",
    "ground_thruth = False\n",
    "pair_sample_ratio = 0.1  # ➔ sample 10% of all possible pairs\n",
    "c = 0.6\n",
    "\n",
    "for state_abstraction, k in state_abstractions:\n",
    "    print(f\"=== State Abstraction: {state_abstraction} with k: {k} ===\")\n",
    "    state_cols, state_cols_simulation, terminal_actions = define_state_cols_sim(state_abstraction, k)\n",
    "    df, df_success, all_cases, all_actions, activity_index_df, n_actions, budget = get_data(dataset, k, state_abstraction)\n",
    "    activity_index = {v: k for k, v in env.activity_meanings.items()}\n",
    "    all_states_unabs = df[state_cols_simulation].drop_duplicates().reset_index(drop=True)\n",
    "    n_states_unabs = len(all_states_unabs)\n",
    "    print(f\"Simulating the environment with {n_states_unabs} distinct original states\")\n",
    "    transition_proba = transition_probabilities_faster_2(df, state_cols_simulation, all_states_unabs, activity_index, n_actions)\n",
    "    all_states_unabs = all_states_unabs.drop(columns=[\"state_index\"])\n",
    "    all_states = df[state_cols].drop_duplicates().reset_index(drop=True)\n",
    "    n_states = len(all_states)\n",
    "    print(f\"Training with {n_states} distinct states ({n_states / n_states_unabs * 100:.2f}%) of original state space) (k={k})\")\n",
    "    all_state_index = {tuple(row): idx for idx, row in all_states.iterrows()}\n",
    "    all_state_unabs_index = {tuple(row): idx for idx, row in all_states_unabs.iterrows()}\n",
    "        \n",
    "    unabs_to_abs_state = {tuple(row[state_cols_simulation]): all_state_index.get(tuple(row[state_cols]), None) \n",
    "                        for _, row in df.iterrows()}\n",
    "\n",
    "    #encode all object (string/categorical) columns\n",
    "    all_states_unabs_encoded = all_states_unabs.copy()\n",
    "    all_states_unabs_encoded['last_action'] = all_states_unabs_encoded['last_action'].map(activity_index)\n",
    "\n",
    "\n",
    "    # === Precompute transitions and encoded states ===\n",
    "    print(\"Precomputing transitions and encoded states...\")\n",
    "    precomputed_transitions = {}\n",
    "    for s in tqdm(range(n_states_unabs), desc=\"States\"):\n",
    "        for a in range(n_actions):\n",
    "            result = get_transitions_and_rewards(s, a, transition_proba)\n",
    "            if not any(x is None for x in result):\n",
    "                precomputed_transitions[(s, a)] = result\n",
    "\n",
    "    encoded_state_array = np.array(all_states_unabs_encoded.values)\n",
    "    scaler = StandardScaler()\n",
    "    encoded_state_array = scaler.fit_transform(encoded_state_array)\n",
    "\n",
    "    # === Group unabstracted states by abstracted state ===\n",
    "    abs_to_unabs = {}\n",
    "    for unabs_state, abs_state in unabs_to_abs_state.items():\n",
    "        if abs_state is not None:\n",
    "            abs_to_unabs.setdefault(abs_state, []).append(unabs_state)\n",
    "    \n",
    "    # ===== Computing bisimulation distance ============\n",
    "    total_bisimilarity_distance = 0\n",
    "    total_weight = 0  \n",
    "    bisim_distances = dict()\n",
    "\n",
    "    with tqdm(abs_to_unabs.items(), desc=\"Computing cluster distances\", unit=\"cluster\") as pbar:\n",
    "            for abs_state, unabs_states in pbar:\n",
    "                if len(unabs_states) <2:\n",
    "                    continue\n",
    "                indices = [all_state_unabs_index[s] for s in unabs_states if s in all_state_unabs_index]\n",
    "                all_pairs = list(combinations(indices, 2))\n",
    "\n",
    "                #sample a subset of pairs\n",
    "                n_sample = min(len(all_pairs), max(1, int(len(all_pairs) * pair_sample_ratio)))\n",
    "                sampled_pairs = random.sample(all_pairs, n_sample)\n",
    "            \n",
    "                bisimilarity_sum = 0\n",
    "                state_size = len(indices)  #cluster size\n",
    "\n",
    "                for idx_i, idx_j in sampled_pairs:\n",
    "                    s_i = idx_i\n",
    "                    s_j = idx_j\n",
    "\n",
    "                    # Get available actions\n",
    "                    possible_actions_i = [a for a in range(n_actions)\n",
    "                                        if (s_i, a) in precomputed_transitions]\n",
    "                    possible_actions_j = [a for a in range(n_actions)\n",
    "                                        if (s_j, a) in precomputed_transitions]\n",
    "                    common_actions = list(set(possible_actions_i) & set(possible_actions_j)) #common action can be empty if terminal states\n",
    "                    all_possible_actions = set(possible_actions_i) | set(possible_actions_j)\n",
    "                \n",
    "                    \n",
    "                    max_action_dist = 0\n",
    "                    for action in all_possible_actions: #abstracted have the same possible actions\n",
    "                            \n",
    "                            result_i = precomputed_transitions.get((s_i, action), ([s_i], [1.0], -100.0))\n",
    "                            result_j = precomputed_transitions.get((s_j, action), ([s_j], [1.0], -100.0))\n",
    "\n",
    "                            next_vecs_i, prob_i, r_i = result_i\n",
    "                            next_vecs_j, prob_j, r_j = result_j\n",
    "\n",
    "                            if isinstance(next_vecs_i[0], (int, np.integer)):\n",
    "                                next_vecs_i = encoded_state_array[next_vecs_i]\n",
    "                            if isinstance(next_vecs_j[0], (int, np.integer)):\n",
    "                                next_vecs_j = encoded_state_array[next_vecs_j]\n",
    "\n",
    "                            reward_diff = abs(r_i - r_j)\n",
    "                            trans_dist = wasserstein_distance_nd(u_values=next_vecs_i, v_values=next_vecs_j, u_weights=prob_i, v_weights=prob_j)\n",
    "                            action_dist = (1-c)*reward_diff + (c*trans_dist)\n",
    "                            max_action_dist = max(max_action_dist, action_dist)\n",
    "                            \n",
    "                    bisimilarity_sum += max_action_dist\n",
    "                    if abs_state not in bisim_distances:\n",
    "                        bisim_distances[abs_state] = dict()\n",
    "                                    \n",
    "                    bisim_distances[abs_state][(idx_i, idx_j)] = max_action_dist\n",
    "\n",
    "                #compute the average bisimilarity distance for this cluster\n",
    "                #average distance for this cluster\n",
    "                avg_bisimilarity_distance = bisimilarity_sum / len(sampled_pairs)\n",
    "\n",
    "                #update total weighted bisimilarity distance\n",
    "                total_bisimilarity_distance += avg_bisimilarity_distance * state_size #with size of cluster\n",
    "                total_weight += state_size\n",
    "\n",
    "                pbar.set_postfix(avg_bisimilarity_distance=f\"{avg_bisimilarity_distance:.2f}\")\n",
    "\n",
    "    #compute the total weighted average bisimilarity distance\n",
    "    weighted_avg_bisimilarity_distance = total_bisimilarity_distance / total_weight\n",
    "    print(f\"Weighted Bisimilarity Distance of {state_abstraction} with {n_states} blocks: {weighted_avg_bisimilarity_distance:.2f}\")\n",
    "\n",
    "    results = {\n",
    "        'weighted_avg_bisimilarity_distance': weighted_avg_bisimilarity_distance,\n",
    "        'bisim_distances': bisim_distances,\n",
    "        'n_states': n_states, \n",
    "        'ratio': pair_sample_ratio\n",
    "    }\n",
    "\n",
    "    script_dir = os.path.dirname(os.path.abspath(\"__file__\"))  \n",
    "    results_dir = os.path.abspath(os.path.join(script_dir, '..', 'results'))\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    filename = f\"bisim_metrics_{dataset}_{state_abstraction}_{k}_{ground_thruth}.pkl\"\n",
    "    file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
