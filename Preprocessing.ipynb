{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter\n",
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPIC12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/pm4py/util/dt_parsing/parser.py:82: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 13087/13087 [00:03<00:00, 3747.52it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"BPI Challenge 2012_1_all\"\n",
    "name = \"BPI_Challenge_2012\"\n",
    "log = xes_importer.apply(path + \"/\" + name + \".xes.gz\")\n",
    "df = converter.apply(log,variant=converter.Variants.TO_DATA_FRAME)\n",
    "\n",
    "df.rename(columns={'concept:name': 'action', \n",
    "                        'case:RequestedAmount': 'amount',\n",
    "                        'case:concept:name': 'ID',\n",
    "                        'time:timestamp':'timestamp'}, inplace=True)\n",
    "\n",
    "#remove incomplete traces\n",
    "cases_to_remove = []\n",
    "for case_id, group in df.groupby('ID'):               \n",
    "        activity_sequence = group['action'].values\n",
    "        if not any(action in activity_sequence for action in ['A_CANCELLED','A_DECLINED','A_APPROVED'] ):\n",
    "                        cases_to_remove.append(case_id)\n",
    "all_cases = df['ID'].unique()\n",
    "df = df[~df['ID'].isin(cases_to_remove)]\n",
    "\n",
    "df['time_since_last_act'] = df.groupby('ID')['timestamp'].diff() #get the time between activities\n",
    "df['time_since_start'] = df.groupby('ID')['timestamp'].transform(lambda x: (x - x.min()).dt.days) #get the time since start of the trace\n",
    "df['time_since_last_act'] = pd.to_timedelta(df['time_since_last_act'])\n",
    "df['NumberOfOffers'] = df.groupby('ID')['action'].transform(lambda x: (x == \"O_CREATED\").cumsum())\n",
    "case_outcome = df.groupby('ID')['action'].apply(lambda x: 'Success' if 'A_APPROVED' in x.values else 'Failure')\n",
    "df['Outcome'] = df['ID'].map(case_outcome)\n",
    "\n",
    "#removing redundant events\n",
    "mask = (\n",
    " \n",
    "    (df['action'] == df.groupby('ID')['action'].shift(1)) &  #check if the previous action is the same\n",
    "    (df['time_since_last_act'] < pd.Timedelta(minutes=5))  #check if time difference is less than 5 minutes\n",
    ")\n",
    "df = df[~mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_mappings = {\n",
    "    'call#': ['W_Nabellen offertes'],\n",
    "    'miss#': ['W_Nabellen incomplete dossiers'],\n",
    "    'offer#': ['O_CREATED'],\n",
    "    'reply#': ['O_SENT_BACK'],\n",
    "    'fix': ['W_Wijzigen contractgegevens']\n",
    "}\n",
    "\n",
    "for hf_feature in hf_mappings.keys():\n",
    "    df[hf_feature] = 0\n",
    "for feature, activities in hf_mappings.items():\n",
    "    df[feature] = df.groupby('ID')['action'].transform(lambda x: x.isin(activities).cumsum())\n",
    "df['fix'] = df['fix'].astype(bool)\n",
    "\n",
    "def classify_amount(amount):\n",
    "    if amount <= 6000:\n",
    "        return 'low'\n",
    "    elif amount > 15000:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'medium'\n",
    "\n",
    "#apply classification to a new column 'amClass' for Branchi et al. (2022) Benchmark\n",
    "df['case:AMOUNT_REQ'] = pd.to_numeric(df['case:AMOUNT_REQ'], errors='coerce')\n",
    "df['amClass'] = df['case:AMOUNT_REQ'].apply(classify_amount)\n",
    "df['last_action'] = df.groupby('ID')['action'].shift(1)\n",
    "df['last_action'] = df['last_action'].fillna(\"Start\")  \n",
    "df['event_number'] = df.groupby('ID').cumcount() \n",
    "\n",
    "environmental_actions = ['O_CANCELLED', \"O_ACCEPTED\", 'O_SENT_BACK']\n",
    "df = df[~df['action'].isin(environmental_actions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'df_bpi2012_preprocessedv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPIC17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 31509/31509 [00:22<00:00, 1414.65it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"BPI Challenge 2017_1_all\"\n",
    "name = \"BPI Challenge 2017\"\n",
    "log = xes_importer.apply(path + \"/\" + name + \".xes.gz\")\n",
    "df = converter.apply(log,variant=converter.Variants.TO_DATA_FRAME)\n",
    "\n",
    "\n",
    "df.rename(columns={'concept:name': 'action', \n",
    "                        'case:LoanGoal': 'goal',\n",
    "                        'case:ApplicationType': 'type',\n",
    "                        'case:RequestedAmount': 'amount',\n",
    "                        'case:concept:name': 'ID',\n",
    "                        'time:timestamp':'timestamp'}, inplace=True)\n",
    "\n",
    "#remove incomplete traces\n",
    "cases_to_remove = []\n",
    "for case_id, group in df.groupby('ID'):               \n",
    "        activity_sequence = group['action'].values\n",
    "        if not any(action in activity_sequence for action in ['A_Cancelled', 'A_Pending', 'A_Denied']):\n",
    "                        cases_to_remove.append(case_id)\n",
    "\n",
    "df = df[~df['ID'].isin(cases_to_remove)]\n",
    "all_cases = df['ID'].unique()\n",
    "\n",
    "# removing infrequent traces\n",
    "df['action'] = df['action'].astype(str)  \n",
    "variants_case = df.groupby('ID')['action'].apply(lambda x: ' -> '.join(x))\n",
    "trace_variants = variants_case.value_counts().reset_index()\n",
    "trace_variants.columns = ['trace_variant', 'frequency']\n",
    "trace_variants['percentage'] = (trace_variants['frequency'] / len(all_cases)) * 100\n",
    "trace_variants['cumulative_percentage'] = trace_variants['percentage'].cumsum()\n",
    "\n",
    "top_80_trace_variants = trace_variants[trace_variants['cumulative_percentage'] <= 80]\n",
    "df['trace_variant'] = df['ID'].map(variants_case)  \n",
    "df= df[df['trace_variant'].isin(top_80_trace_variants['trace_variant'])]\n",
    "df = df.drop(columns=['trace_variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_since_last_act'] = df.groupby('ID')['timestamp'].diff() \n",
    "df['time_since_start'] = df.groupby('ID')['timestamp'].transform(lambda x: (x - x.min()).dt.days) \n",
    "df['time_since_last_act'] = pd.to_timedelta(df['time_since_last_act'])\n",
    "df['NumberOfOffers'] = df.groupby('ID')['action'].transform(lambda x: (x == \"O_Create Offer\").cumsum())\n",
    "case_outcome = df.groupby('ID')['action'].apply(lambda x: 'Success' if 'A_Pending' in x.values else 'Failure')\n",
    "df['Outcome'] = df['ID'].map(case_outcome)\n",
    "\n",
    "#identify consecutive duplicate actions that meet the conditions\n",
    "mask = (\n",
    "    (df['EventOrigin'] == 'Workflow') & \n",
    "    (df['action'] == df.groupby('ID')['action'].shift(1)) &  \n",
    "    (df['time_since_last_act'] < pd.Timedelta(minutes=5))  #check if time difference is less than 5 minutes\n",
    ")\n",
    "df = df[~mask].reset_index(drop=True)\n",
    "\n",
    "nan_col = ['FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'Selected', 'CreditScore', 'OfferedAmount',\n",
    "       'time_since_start']\n",
    "for col in nan_col:\n",
    "    df[col] = df[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_mappings = {\n",
    "    'call#': ['W_Call after offers'],\n",
    "    'miss#': ['W_Call incomplete files'],\n",
    "    'offer#': ['O_Create Offer'],\n",
    "    'reply#': ['O_Returned']\n",
    "}\n",
    "\n",
    "for hf_feature in hf_mappings.keys():\n",
    "    df[hf_feature] = 0\n",
    "\n",
    "for feature, activities in hf_mappings.items():\n",
    "    df[feature] = df.groupby('ID')['action'].transform(lambda x: x.isin(activities).cumsum())\n",
    "\n",
    "\n",
    "df['last_action'] = df.groupby('ID')['action'].shift(1)\n",
    "df['last_action'] = df['last_action'].fillna(\"Start\") \n",
    "df['event_number'] = df.groupby('ID').cumcount() \n",
    "\n",
    "environmental_actions = ['O_Accepted', 'O_Cancelled', 'O_Returned']\n",
    "df = df[~df['action'].isin(environmental_actions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'df_bpi2017_preprocessedv2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
