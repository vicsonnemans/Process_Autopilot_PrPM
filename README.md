# Process Autopilot: Intelligent Decision-Making for Improved Process Outcomes

Traditional process mining primarily focuses on descriptive, diagnostic, and predictive analytics but lacks mechanisms for prescriptive optimization of business processes. Recently, various approaches to prescriptive process monitoring have been proposed, which mostly focus on defining ad-hoc abstractions of the process states over event data. However, a systematic, theoretic approach to reduce the high-dimensional space of processes while maintaining sufficient information for decision-making is still lacking.

In this paper, we introduce Process Autopilot, an offline-to-online Reinforcement Learning (RL) framework that leverages state abstraction for autonomously learning optimal decision strategies that maximize future process outcomes in a non-deterministic and stochastic environment. Our approach involves the discovery of a high-dimensional Markov Decision Process (MDP) from an input event log. The framework introduces and benchmarks multiple state abstraction strategies for automatically reducing the MDPâ€™s state space, aiming to enhance the generalization of offline RL to process conditions beyond the training data. The offline policies trained on the abstracted MDP are then transferred to an online RL agent to accelerate learning. Evaluations on industrial event logs, using our publicly available implementation, demonstrate the effectiveness of abstraction functions that preserve essential state transition information while maintaining sufficient flexibility for generalization. Our results show that Process Autopilot with appropriate abstraction uncovers superior decision-making strategies, leading to a significant uplift in process outcomes.
