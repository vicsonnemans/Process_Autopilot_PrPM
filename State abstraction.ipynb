{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import dok_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import os\n",
    "from MDP_functions import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(df, state_cols, k):\n",
    "\n",
    "    all_states_abs = df[[\"last_action\"] + state_cols + control_var].drop_duplicates().reset_index(drop=True)\n",
    "    n_states_abs = len(all_states_abs)\n",
    "\n",
    "    print(f\"Number of distinct states for {state_cols}: {n_states_abs}\")\n",
    "    df_selected = df[state_cols]\n",
    "\n",
    "    #convert categorical variables\n",
    "    categorical_columns = df_selected.select_dtypes(include=['object']).columns.tolist()\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df_selected[categorical_columns])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "    df_selected = df_selected.reset_index(drop=True)\n",
    "    one_hot_df = one_hot_df.reset_index(drop=True)\n",
    "    df_encoded = pd.concat([df_selected, one_hot_df], axis=1)\n",
    "    state_cols = list(df_encoded.drop(categorical_columns, axis=1).columns) \n",
    "    df_encoded = df_encoded.drop(categorical_columns, axis=1)\n",
    "    df_encoded[state_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    #apply k-means clustering on the event attributes\n",
    "    kmeanModel = KMeans(n_clusters=k, random_state=42).fit(df_encoded)\n",
    "    df_encoded['cluster'] = kmeanModel.labels_\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['cluster']=df_encoded['cluster'] #add clusters to df\n",
    "    all_states_abs = df[['last_action',\"cluster\"]+control_var].drop_duplicates().reset_index(drop=True)\n",
    "    n_states_abs = len(all_states_abs)\n",
    "\n",
    "    print(f\"Number of distinct states for {k} clusters: {n_states_abs}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change parameters:\n",
    "dataset = 'bpi2012'\n",
    "state_abstraction = 'k_means_features'\n",
    "df = pd.read_csv(f'df_{dataset}_preprocessedv2.csv', sep=\",\")\n",
    "\n",
    "if dataset == 'bpi2017':\n",
    "    control_var = ['call#', 'miss#', 'offer#', 'reply#']\n",
    "    if state_abstraction == 'k_means_features':\n",
    "        state_cols = ['goal', 'type', 'amount', 'NumberOfTerms',\n",
    "        'FirstWithdrawalAmount', 'Accepted', 'MonthlyCost',\n",
    "        'Selected', 'CreditScore', 'OfferedAmount', 'time_since_start']\n",
    "    elif state_abstraction == 'k_means':\n",
    "        state_cols  = ['goal', 'type', 'amount', 'NumberOfTerms',\n",
    "        'FirstWithdrawalAmount', 'Accepted', 'MonthlyCost',\n",
    "        'Selected', 'CreditScore', 'OfferedAmount', 'time_since_start'] + ['call#', 'miss#', 'offer#', 'reply#']\n",
    "    \n",
    "    \n",
    "elif dataset == 'bpi2012':\n",
    "    if state_abstraction == 'k_means_features':\n",
    "        state_cols = ['case:AMOUNT_REQ', 'time_since_start']\n",
    "    elif state_abstraction == 'k_means':\n",
    "        state_cols = ['case:AMOUNT_REQ', 'time_since_start']+['call#', 'miss#', 'offer#', 'reply#', 'fix']\n",
    "    control_var = ['call#', 'miss#', 'offer#', 'reply#', 'fix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct states for ['case:AMOUNT_REQ', 'time_since_start']: 60067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/vsonnemans/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct states for 200 clusters: 31571\n"
     ]
    }
   ],
   "source": [
    "#K-means\n",
    "k = 200\n",
    "df_abs = k_means(df, state_cols, k)\n",
    "if state_abstraction == 'k_means':\n",
    "    df_abs.to_csv(f'df_{dataset}_{k}_clusters.csv', index=False)\n",
    "elif state_abstraction == 'k_means_features':\n",
    "    df_abs.to_csv(f'df_{dataset}_{k}_clusters_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural state abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240337 distinct states in original state space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cases: 100%|██████████| 25128/25128 [00:40<00:00, 627.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#change parameters:\n",
    "dataset = 'bpi2017'\n",
    "state_abstraction = False\n",
    "k = None\n",
    "benchmark = False\n",
    "\n",
    "#unabstracted MDP\n",
    "df, df_success, all_cases, all_actions, activity_index, n_actions, budget = get_data(dataset, k, state_abstraction)\n",
    "state_cols, state_cols_simulation, terminal_actions = define_state_cols(dataset, df, k, state_abstraction, benchmark, activity_index)\n",
    "all_states = df[state_cols].drop_duplicates().reset_index(drop=True)\n",
    "n_states = len(all_states)\n",
    "print(f\"{n_states} distinct states in original state space\")\n",
    "transition_proba = transition_probabilities_faster(df, state_cols, all_states, activity_index, n_actions)\n",
    "\n",
    "all_states['state_index'] = all_states.index\n",
    "state_index_map = {\n",
    "                (tuple(row[state_cols])): row['state_index']\n",
    "                for _, row in all_states.iterrows()\n",
    "            }\n",
    "df[\"state\"] = df[state_cols].apply(lambda row: state_index_map.get(tuple(row), -1), axis=1)\n",
    "df[\"next_state\"] = df.groupby(\"ID\")[\"state\"].shift(-1).fillna(-1).astype(int)\n",
    "\n",
    "state_action_map = defaultdict(set)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    state_action_map[row[\"state\"]].add((row[\"action\"], row[\"next_state\"]))\n",
    "\n",
    "#identify unique state groups\n",
    "unique_state_groups = {}\n",
    "merged_state_index = 0\n",
    "\n",
    "for state, action_next_pairs in state_action_map.items():\n",
    "    action_next_pairs = tuple(sorted(action_next_pairs))\n",
    "    \n",
    "    #assign a merged state index if not already assigned\n",
    "    if action_next_pairs not in unique_state_groups:\n",
    "        unique_state_groups[action_next_pairs] = merged_state_index\n",
    "        merged_state_index += 1\n",
    "\n",
    "#create a new column for merged states\n",
    "df[\"cluster\"] = df[\"state\"].map(lambda s: unique_state_groups.get(tuple(sorted(state_action_map.get(s, set()))), -1))\n",
    "\n",
    "print(f\"Abstracted state size: {len(df['cluster'].unique())}\")\n",
    "df.to_csv(f'df_{dataset}_{k}_structural.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
